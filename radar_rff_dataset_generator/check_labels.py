#!/usr/bin/env python
"""
å¿«é€Ÿæ£€æŸ¥æ•°æ®é›†æ ‡ç­¾çš„è„šæœ¬

è¿è¡Œæ–¹å¼ï¼š
    python check_labels.py
    python check_labels.py --dataset-path ./radar_rff_dataset_realistic/radar_rff_dataset.h5
"""
import h5py
import numpy as np
import argparse
import os

def check_labels(dataset_path):
    """æ£€æŸ¥æ•°æ®é›†æ ‡ç­¾"""
    
    if not os.path.exists(dataset_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ•°æ®é›†æ–‡ä»¶: {dataset_path}")
        print(f"   è¯·å…ˆç”Ÿæˆæ•°æ®é›†")
        return
    
    print("\n" + "="*80)
    print("ğŸ” æ•°æ®é›†æ ‡ç­¾æ£€æŸ¥")
    print("="*80)
    print(f"æ–‡ä»¶: {dataset_path}")
    
    # æ‰“å¼€æ•°æ®é›†
    with h5py.File(dataset_path, 'r') as f:
        # æ˜¾ç¤ºæ‰€æœ‰æ•°æ®é›†
        print("\nğŸ“‚ HDF5æ–‡ä»¶ä¸­çš„æ•°æ®é›†:")
        for key in f.keys():
            shape = f[key].shape
            dtype = f[key].dtype
            print(f"   {key:<25} shape={shape}, dtype={dtype}")
        
        # è¯»å–æ ‡ç­¾
        iq_data = f['iq_data']
        device_labels = f['device_labels'][:]
        modulation_labels = f['modulation_labels'][:]
        combined_labels = f['combined_labels'][:]
        snr_db = f['snr_db'][:]
        
        total_samples = len(device_labels)
        
        print("\n" + "="*80)
        print("ğŸ“Š æ ‡ç­¾ç»Ÿè®¡ä¿¡æ¯")
        print("="*80)
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"\næ€»æ ·æœ¬æ•°: {total_samples:,}")
        print(f"IQæ•°æ®shape: {iq_data.shape}")
        print(f"IQæ•°æ®dtype: {iq_data.dtype}")
        
        # è®¾å¤‡æ ‡ç­¾
        print(f"\nğŸ“± è®¾å¤‡æ ‡ç­¾ (device_labels):")
        print(f"   èŒƒå›´: {device_labels.min()} ~ {device_labels.max()}")
        print(f"   å”¯ä¸€è®¾å¤‡æ•°: {len(np.unique(device_labels))} ä¸ª")
        device_counts = np.bincount(device_labels)
        print(f"   æ¯ä¸ªè®¾å¤‡çš„æ ·æœ¬æ•°:")
        for dev_id, count in enumerate(device_counts):
            print(f"      è®¾å¤‡ {dev_id:2d} (Radar_Device_{dev_id+1:02d}): {count:7,} æ ·æœ¬")
        
        # è°ƒåˆ¶æ ‡ç­¾
        print(f"\nğŸ“¡ è°ƒåˆ¶æ ‡ç­¾ (modulation_labels):")
        print(f"   èŒƒå›´: {modulation_labels.min()} ~ {modulation_labels.max()}")
        print(f"   å”¯ä¸€è°ƒåˆ¶æ•°: {len(np.unique(modulation_labels))} ç§")
        modulation_counts = np.bincount(modulation_labels)
        
        # 26ç§è°ƒåˆ¶çš„åç§°ï¼ˆæŒ‰ç…§é…ç½®é¡ºåºï¼‰
        modulation_names = [
            # QAMç³»åˆ— (4ç§)
            '16qam', '64qam', '256qam', '1024qam',
            # PSKç³»åˆ— (5ç§)
            'bpsk', 'qpsk', '8psk', '16psk', '32psk',
            # FSKç³»åˆ— (4ç§)
            '2fsk', '4fsk', '8fsk', '16fsk',
            # GFSKç³»åˆ— (4ç§)
            '2gfsk', '4gfsk', '8gfsk', '16gfsk',
            # MSKç³»åˆ— (4ç§)
            '2msk', '4msk', '8msk', '16msk',
            # AMç³»åˆ— (4ç§)
            'am-dsb', 'am-dsb-sc', 'am-lsb', 'am-usb',
            # FMç³»åˆ— (1ç§)
            'fm'
        ]
        
        print(f"   æ¯ç§è°ƒåˆ¶çš„æ ·æœ¬æ•°:")
        for mod_id, count in enumerate(modulation_counts):
            mod_name = modulation_names[mod_id] if mod_id < len(modulation_names) else 'unknown'
            print(f"      è°ƒåˆ¶ {mod_id:2d} ({mod_name:<15}): {count:7,} æ ·æœ¬")
        
        # ç»„åˆæ ‡ç­¾
        print(f"\nğŸ”— ç»„åˆæ ‡ç­¾ (combined_labels):")
        print(f"   èŒƒå›´: {combined_labels.min()} ~ {combined_labels.max()}")
        print(f"   å”¯ä¸€ç±»åˆ«æ•°: {len(np.unique(combined_labels))} ç±»")
        combined_counts = np.bincount(combined_labels)
        samples_per_class = combined_counts[0]
        print(f"   æ¯ç±»æ ·æœ¬æ•°: {samples_per_class:,} (åº”è¯¥å…¨éƒ¨ç›¸åŒ)")
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç±»åˆ«æ ·æœ¬æ•°ç›¸åŒ
        if np.all(combined_counts == samples_per_class):
            print(f"   âœ… æ‰€æœ‰ç±»åˆ«æ ·æœ¬æ•°å‡ä¸º {samples_per_class}")
        else:
            print(f"   âš ï¸  ç±»åˆ«æ ·æœ¬æ•°ä¸ä¸€è‡´ï¼")
            unique_counts = np.unique(combined_counts)
            print(f"   æ ·æœ¬æ•°åˆ†å¸ƒ: {unique_counts}")
        
        # SNRä¿¡æ¯
        print(f"\nğŸ“¶ SNRä¿¡æ¯ (snr_db):")
        print(f"   èŒƒå›´: {snr_db.min():.2f} ~ {snr_db.max():.2f} dB")
        print(f"   å¹³å‡å€¼: {snr_db.mean():.2f} dB")
        print(f"   ä¸­ä½æ•°: {np.median(snr_db):.2f} dB")
        print(f"   æ ‡å‡†å·®: {snr_db.std():.2f} dB")
        
        # æ˜¾ç¤ºå‰10ä¸ªæ ·æœ¬
        print(f"\nğŸ“‹ å‰10ä¸ªæ ·æœ¬çš„æ ‡ç­¾ç¤ºä¾‹:")
        print(f"   {'ç´¢å¼•':<8} {'è®¾å¤‡ID':<10} {'è°ƒåˆ¶ID':<10} {'ç»„åˆID':<10} {'SNR(dB)':<10}")
        print("   " + "-"*60)
        for i in range(min(10, total_samples)):
            print(f"   {i:<8} {device_labels[i]:<10} {modulation_labels[i]:<10} "
                  f"{combined_labels[i]:<10} {snr_db[i]:<10.2f}")
        
        # éªŒè¯ç»„åˆIDè®¡ç®—
        print(f"\nğŸ” éªŒè¯ç»„åˆIDè®¡ç®—å…¬å¼:")
        print(f"   å…¬å¼: combined_id = device_id * 26 + modulation_id")
        
        calculated_combined = device_labels * 26 + modulation_labels
        if np.all(calculated_combined == combined_labels):
            print(f"   âœ… æ‰€æœ‰ç»„åˆIDè®¡ç®—æ­£ç¡®")
        else:
            print(f"   âŒ ç»„åˆIDè®¡ç®—æœ‰è¯¯ï¼")
            mismatch_count = np.sum(calculated_combined != combined_labels)
            print(f"   ä¸åŒ¹é…çš„æ ·æœ¬æ•°: {mismatch_count}")
        
        # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        print(f"\nâœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥:")
        print(f"   è®¾å¤‡IDèŒƒå›´æ­£ç¡®: {0 <= device_labels.min() and device_labels.max() < 20}")
        print(f"   è°ƒåˆ¶IDèŒƒå›´æ­£ç¡®: {0 <= modulation_labels.min() and modulation_labels.max() < 26}")
        print(f"   ç»„åˆIDèŒƒå›´æ­£ç¡®: {0 <= combined_labels.min() and combined_labels.max() < 520}")
        print(f"   æ‰€æœ‰æ ‡ç­¾é•¿åº¦ä¸€è‡´: {len(device_labels) == len(modulation_labels) == len(combined_labels)}")
        
        # æ•°æ®é›†è´¨é‡è¯„ä¼°
        print(f"\nğŸ“ˆ æ•°æ®é›†è´¨é‡è¯„ä¼°:")
        num_devices = len(np.unique(device_labels))
        num_modulations = len(np.unique(modulation_labels))
        num_classes = len(np.unique(combined_labels))
        expected_classes = num_devices * num_modulations
        
        print(f"   è®¾å¤‡æ•°: {num_devices} (æœŸæœ›: 20)")
        print(f"   è°ƒåˆ¶æ•°: {num_modulations} (æœŸæœ›: 26)")
        print(f"   æ€»ç±»åˆ«æ•°: {num_classes} (æœŸæœ›: {expected_classes})")
        print(f"   æ¯ç±»æ ·æœ¬æ•°: {samples_per_class:,}")
        
        if num_classes == expected_classes and samples_per_class > 0:
            print(f"\n   ğŸ‰ æ•°æ®é›†å®Œæ•´ä¸”ç¬¦åˆé¢„æœŸï¼")
        else:
            print(f"\n   âš ï¸  æ•°æ®é›†å¯èƒ½ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥")
        
        print("\n" + "="*80)

def main():
    parser = argparse.ArgumentParser(description='æ£€æŸ¥é›·è¾¾RFFæ•°æ®é›†æ ‡ç­¾')
    parser.add_argument('--dataset-path', 
                       default='./radar_rff_dataset_realistic/radar_rff_dataset.h5',
                       help='æ•°æ®é›†HDF5æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    check_labels(args.dataset_path)

if __name__ == '__main__':
    main()

